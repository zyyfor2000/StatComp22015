---
title: "Introduction to StatComp22015"
author: "22015"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to StatComp22015}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## Overview

__StatComp22015__ is a simple R package developed to compare the performance of R and R++ (implemented through the R package _Rcpp_) for the 'Statistical Computing' course. Two functions are considered, namely, _gibbs_ (generate random nubers using Gibbs sampler) and _rwMetropolis_ (A random walk Metropolis sampler for t distribution). For each function, both R and Rcpp versions are produced. Namely _gibbsR_ and  _rwMetropolisR_ for R and _gibbC_ and _rwMetropolisC_ for C++.

The R package 'microbenchmark' can be used to benchmark the above R and C++ functions.

Besides, __StatComp22015__ also includes my simulation graphic results. The plot procedure is finished by R and the calculation is finished by Python which you can find [here](https://github.com/zyyfor2000/code)


```{r,eval=TRUE}
library(StatComp22015)
library(microbenchmark)
```

The above results show an evident computational speed gain of C++ against R.


## Benchmarking _gibbsR_ and _gibbsC_

The source R code for _gibbsR_ is as follows:
```{r,eval=FALSE}
gibbsR = function(N,burn,thin,mu1,mu2,sigma1,sigma2,rho) {
  mat = matrix(0,nrow = N, ncol = 2)
  mat[1,] = c(mu1,mu2)
  s1 = sqrt(1-rho^2)*sigma1
  s2 = sqrt(1-rho^2)*sigma2
  for (i in 2:N) {
    for (j in 1:thin) {
      y = mat[i-1, 2]
      m1 = mu1 + rho * (y - mu2) * sigma1/sigma2
      x = rnorm(1, m1, s1)
      m2 = mu2 + rho * (x - mu1) * sigma2/sigma1
      y = rnorm(1, m2, s2)
    }
    mat[i, ] = c(x, y)
  }
  mat[(burn+1):N,]
}
```

The above R code involves two loops, which could be very slow even for R-3.01 or any higher version. The corresponding C++ code is as follows.

```{r,eval=FALSE}
NumericMatrix gibbsC(int N,int burn, int thin, double mu1, double mu2,double sigma1,double sigma2,double rho) {
  NumericMatrix mat(N, 2);
  double m1,m2;
  double x = mu1, y = mu2;
  mat(0,0) = x;
  mat(0,1) = y;
  double s1 = sqrt(1-pow(rho,2))*sigma1;
  double s2 = sqrt(1-pow(rho,2))*sigma2;
  for(int i = 1; i < N; i++) {
    for(int j = 0; j < thin; j++) {
      y = mat(j-1, 2);
      m1 = mu1 + rho * (y - 0) * sigma1/sigma2;
      x = rnorm(1, m1, s1)[0];
      m2 = mu2 + rho * (x - 0) * sigma2/sigma1;
      y = rnorm(1, m2, s2)[0];
    }
    mat(i, 0) = x;
    mat(i, 1) = y;
  }
  NumericMatrix mlast = mat( Range(burn,N-1) ,Range(0,1));
  return(mlast);
}
```

The R code for benchmarking _gibbsR_ and _gibbsC_ is as follows.

```{r,eval=TRUE}
tm1 = microbenchmark(
  gR = gibbsR(1000,100,1,0,0,1,1,0.9),
  gC = gibbsC(1000,100,1,0,0,1,1,0.9)
)
knitr::kable(summary(tm1)[,c(1,3,5,6)])
```

The results again show an evident computational speed gain of C++ against R.

## Benchmarking _rwMetropolisR_ and _rwMetropolisC_

The source R code for _rwMetropolisR_ is as follows:
```{r,eval=FALSE}
rwMetropolisR = function(n, sigma, x0, N, burn) {
    x = numeric(N)
    x[1] = x0
    u = runif(N)
    for (i in 2:N) {
    y = rnorm(1, x[i-1], sigma)
    if (u[i] <= (dt(y, n) / dt(x[i-1], n)))
      x[i] = y  
    else {
      x[i] = x[i-1]
    }
  }
  return(x[(burn+1):N])
}
```

The corresponding C++ code is as follows.

```{r,eval=FALSE}
NumericVector rwMetropolisC(int n, double sigma, double x0, int N, int burn) {
  NumericVector x(N);
  x[1] = x0;
  for (int i = 1; i < N; i++) {
    double u = runif(1)[0];
    double y = rnorm(1, x[i-1], sigma)[0];
    double tmp1 = ::Rf_dt(y, n, 0) ;
    double tmp2 = ::Rf_dt(x[i-1], n, 0);
    double tmp = tmp1/tmp2;
    if (u <= tmp){
      x[i] = y  ;
    }
      else {
        x[i] = x[i-1];
      }
  }
  NumericVector xlast = x[Range(burn,N-1)];
  return(xlast);
}
}
```

The R code for benchmarking _rwMetropolisR_ and _rwMetropolisC_ is as follows.

```{r,eval=TRUE}
tm1 = microbenchmark(
  rR = rwMetropolisR(2,1,1,1000,100),
  rC = rwMetropolisC(2,1,1,1000,100)
)
knitr::kable(summary(tm1)[,c(1,3,5,6)])
```

The results again show an evident computational speed gain of C++ against R.


## Graphical displays of my simulation result: _plot_s_


In the paper called A general method for addressing forecasting uncertainty in inventory models, 3 methods have been proposed to solve the question below.
$$
\begin{equation}
	TC(S_n) = h*E(S_n -D_{[n+1,n+L]})^+ +b*E(S_n -D_{[n+1,n+L]})^-
\end{equation}
$$

All the three methods are about parameter methods. Then  I apply 6 methods about nonparameter methods to compare.

To reproduce the table in papar, I present graphical displays of the table in the paper as follows.

```{r,eval=FALSE}
plot_s = function(counter,result){
  sigma = c(1:10)
  par(mai = c(0.8,0.8,0.8,1))
  n_total = c(5,10,20,100)
  plot(c(1:9),result[1,counter,],type = "l",col=1,ylim=c(min(result[,counter,]-5),max(result[,counter,])+5),ylab = "total cost" ,xlab = "method",main = bquote(n == .(n_total[counter])))
  axis(1,"m",at = seq(1,9,1),labels = TRUE)
  for (i in 2:10){
    lines(result[i,counter,],type = "l",col=i)
  }
  usr = par("usr")
  x = usr[2]*1.02
  y = usr[4]*0.9
  legend(x,y, legend = sigma,lty=1,col = 1:10,ncol = 1,title = expression(sigma^2),xpd = TRUE)
}
```

Let's see how my simulation takes on.

```{r}
# my results are imported as data existed
result = array(data = 0, dim = c(10,4,9))
for (i in 1:10){
  a = read.table(paste("../data/text",i,".txt",sep = ""))
  a = a[,c(2,1,3,4,5,6,7,8,9)]
  result[i,,] = as.matrix(a)
}

```


```{r}
plot_s(1,result)
```

```{r}
plot_s(2,result)
```

```{r}
plot_s(3,result)
```

```{r}
plot_s(4,result)
```

